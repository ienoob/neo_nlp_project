{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word embedding\n",
    "词向量模型，主要功能是用于表示\n",
    "\n",
    "参考\n",
    "1）cs224n 第二讲和第三讲\n",
    "2）speech and language processing chapter 16 -- semantic with dense vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本表征的方法\n",
    "文本表征的目的是将文本转化成机器学习算法可以处理的数字形式，换句话说就是将文本使用数学语言进行表示。\n",
    "- 词袋模型 one-hot\\tf-idf\n",
    "- 主题模型，LSA\\PLSA\\LDA等\n",
    "- 词向量模型 word2vec fastText glove\n",
    "- 动态词向量模型 elmo BERT GPT\n",
    "\n",
    "词向量模型将一个词表示成一个先对要短（1000以内的长度）以及稠密的向量（大部分值不为0）\n",
    "词袋模型简单，但是存在维数灾难和语义鸿沟的问题\n",
    "主题模型训练计算复杂度高\n",
    "早期的词向量的研究源于语言模型，比附NNLM和RNNLM, 词向量是副产物。\n",
    "**语言模型，就是用来计算一个词序列的概率的模型。**\n",
    "\n",
    "\n",
    "分布式假设：相同上下文语境的词具有相似含义，并且由此引出了word2vec和fastText等。这类词向量中，虽然其本质仍然是语言模型，但其目标是\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gutenberg.words(\"austen-emma.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Emma']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_id = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
