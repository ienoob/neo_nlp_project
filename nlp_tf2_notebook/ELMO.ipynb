{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## ELMo的优势\n",
    "（1）ELMo能够学习到词汇用法的复杂性，比如语法、语义\n",
    "（2）ELMo能够学习不同上下文情况下的词汇多义性\n",
    "\n",
    "基于大量文本，ELMo模型时从深层的双向语言模型（deep bidirectional language model）中内部状态（internal state）学习而来的，而这些词向量很容易加入到QA、文本对齐，文本分类等任务中。\n",
    "\n",
    "语言模型就是生成文本的模型，是多个N个词语的序列$(t_1,t_2,...,t_N)$前向语言模型就是，已知$(t_1,t_2,...,t_{k-1})$，预测下一个词语$t_k$的概率是：\n",
    "$p(t_1,t_2,...,t_N)=\\prod_{k=1}^{N}{p(t_k|t_1,t_2,...,t_{k-1})}$\n",
    "后向语言模型如下，即通过下文预测之前：\n",
    "$p(t_1,t_2,...,t_N)=\\prod_{k=1}^{N}{p(t_k|t_{k+1},t_{k+2},...,t_N}$\n",
    "\n",
    "双向语言模型将前后向语言模型结合起来，最大化前向、后向模型的联合似然函数，\n",
    "如下所示：\n",
    "$\\sum_{k=1}^{N}{(logp(t_k|t_2,...,t_{k-1};\\theta,\\vec{\\theta_{LSTM}},\\theta_s)+logp(t_k|t_{k+1},t_{k+2},...,t_N;\\theta,\\overleftarrow{\\theta_{LSTM}},\\theta_{s}))}$\n",
    "\n",
    "ELMo是双向语言模型biLM的多层表示的组合，对于某一个词语$t_k$, 一个L层的双向语言模型biLM能够由2L+1个相连表示：\n",
    "$R_k={X^{LM},\\overleftarrow{h_k^{LMj}},\\overrightarrow{h_k^{LMj}}|j=1,...,L}=\\{h_k^{LMj},|j=1,...,L\\}$\n",
    "其中${h_k^{LMj}}=[\\overrightarrow{h_k^{LMj}};\\overleftarrow{h_k^{LMj}}]$\n",
    "\n",
    "ELMo将多层的BiLM的输出R整合成一个向量，$ELMo_k=E(R_k;\\theta_e)$.最简单的情况是ELMo仅使用最顶层的输出，即$E(R_k)=h_k^{LM,L}$，类似于TagLM和CoVe模型。但是最好的ELMo模型是将所有BiLM层的输出加上normalized的softmax学到的权重\n",
    "$s=Softmax(w)$\n",
    "$E(R_k;w,\\gamma)=\\gamma\\sum_{j=0}^{L}{s_jh_k^{LMj}}$\n",
    "其中$\\gamma$是缩放因子。加入每一个BiLM的输出具有不同的分布，$\\gamma$某种程度上来说相当于在weighting前对每一层BiLM使用layer normalization\n",
    "\n",
    "## 如何使用ELMo的词向量\n",
    "（1）直接将ELMo词向量ELMo_k 和普通的词向量x_k拼接（concat）$[x_k;ELMo_k]$\n",
    "（2）直接将ELMo词向量ELMo_k 与隐层输出向量h_h拼接$[h_k;ELMo_k]$, 在SNLI, SQuAD上都有提升。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考 https://github.com/strongio/keras-elmo/blob/master/Elmo%20Keras.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_directory_data(directory):\n",
    "    data = {}\n",
    "    data[\"sentence\"] = []\n",
    "    data[\"sentiment\"] = []\n",
    "    for file_path in os.listdir(directory):\n",
    "        with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
    "            data[\"sentence\"].append(f.read())\n",
    "            data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
    "    return pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge positive and negative examples, add a polarity column and shuffle.\n",
    "def load_dataset(directory):\n",
    "    pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
    "    neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
    "    pos_df[\"polarity\"] = 1\n",
    "    neg_df[\"polarity\"] = 0\n",
    "    return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and process the dataset files.\n",
    "def download_and_load_datasets(force_download=False):\n",
    "    dataset = tf.keras.utils.get_file(\n",
    "      fname=\"aclImdb.tar.gz\", \n",
    "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
    "      extract=True)\n",
    "\n",
    "    train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
    "                                       \"aclImdb\", \"train\"))\n",
    "    test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
    "                                      \"aclImdb\", \"test\"))\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "  417792/84125825 [..............................] - ETA: 57:08"
     ]
    }
   ],
   "source": [
    "train_df, test_df = download_and_load_datasets()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElmoEmbeddingLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.dimensions = 1024\n",
    "        self.trainable=True\n",
    "        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=self.trainable,\n",
    "                               name=\"{}_module\".format(self.name))\n",
    "\n",
    "        self.trainable_weights += K.tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n",
    "        super(ElmoEmbeddingLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n",
    "                      as_dict=True,\n",
    "                      signature='default',\n",
    "                      )['default']\n",
    "        return result\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return K.not_equal(inputs, '--PAD--')\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(): \n",
    "    input_text = layers.Input(shape=(1,), dtype=\"string\")\n",
    "    embedding = ElmoEmbeddingLayer()(input_text)\n",
    "    dense = layers.Dense(256, activation='relu')(embedding)\n",
    "    pred = layers.Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "    model = Model(inputs=[input_text], outputs=pred)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets (Only take up to 150 words for memory)\n",
    "train_text = train_df['sentence'].tolist()\n",
    "train_text = [' '.join(t.split()[0:150]) for t in train_text]\n",
    "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
    "train_label = train_df['polarity'].tolist()\n",
    "\n",
    "test_text = test_df['sentence'].tolist()\n",
    "test_text = [' '.join(t.split()[0:150]) for t in test_text]\n",
    "test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
    "test_label = test_df['polarity'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.fit(train_text, \n",
    "          train_label,\n",
    "          validation_data=(test_text, test_label),\n",
    "          epochs=1,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_save_preds = model.predict(test_text[0:100]) # predictions before we clear and reload model\n",
    "\n",
    "# Clear and load model\n",
    "model = None\n",
    "model = build_model()\n",
    "model.load_weights('ElmoModel.h5')\n",
    "\n",
    "post_save_preds = model.predict(test_text[0:100]) # predictions after we clear and reload model\n",
    "all(pre_save_preds == post_save_preds) # Are they the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
